# Realtime--TFOD: Real-Time Gesture Detection
  
Realtime-TFOD is a system that performs real-time gesture detection and classification using computer vision and deep learning. This project focuses on recognizing specific hand gestures such as hello, thumbs-up, thumbs-down, and namaste, providing a robust platform for intuitive interaction between humans and machines.

#### Key features include:

- Gesture Detection: Detect and classify hand gestures in real-time.
- Real-Time Analysis: Process video streams to provide instant feedback.
- Deep Learning Models: Utilize advanced deep learning techniques for accurate gesture recognition.
- Customizable Labels: Expand or modify the gesture labels as needed for specific use cases.
- Versatile Applications: Suitable for interactive kiosks, sign language interpretation, robotics, and other human-computer interaction scenarios.

## Technologies Used
- Computer Vision
- Deep Learning
- TensorFlow
- OpenCV
- Python

## Demo

![GestureDetection](https://github.com/user-attachments/assets/17a3d3c6-cd4f-4140-96c8-5074dce61060)


https://github.com/user-attachments/assets/c95d2bac-58d4-45d3-87df-5a72715ec65d

## How to Run This Project

1. Clone the repository:
```
git clone https://github.com/Chauhan-Aman/Realtime--TFOD.git
cd realtime-tfod
```
2. Set up a virtual environment:
```
python -m venv venv
source venv/bin/activate.ps1   # On Windows use `venv\Scripts\activate.ps1`
```
3. Install required dependencies:
```
Install required dependencies:
```
4. Create Your Gesture Dataset:
```
Run the Script Image Collection.ipynb
```
5. Train the model and do realtime gesture detection
```
Run the Script Training and Detection.ipynb
```

This setup will allow you to run the Human Emotion Detection system locally.
