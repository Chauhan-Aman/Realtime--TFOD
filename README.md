# Realtime--TFOD: Real-Time Gesture Detection
  
Realtime-TFOD is a system that performs real-time gesture detection and classification using computer vision and deep learning. This project focuses on recognizing specific hand gestures such as hello, thumbs-up, thumbs-down, and namaste, providing a robust platform for intuitive interaction between humans and machines.

#### Key features include:

- Gesture Detection: Detect and classify hand gestures in real-time.
- Real-Time Analysis: Process video streams to provide instant feedback.
- Deep Learning Models: Utilize advanced deep learning techniques for accurate gesture recognition.
- Customizable Labels: Expand or modify the gesture labels as needed for specific use cases.
- Versatile Applications: Suitable for interactive kiosks, sign language interpretation, robotics, and other human-computer interaction scenarios.

## Technologies Used
- Computer Vision
- Deep Learning
- TensorFlow
- OpenCV
- Python

## Demo

![GestureDetection](https://github.com/user-attachments/assets/c77bfeff-aab2-4ea0-a9cc-7fd940061309)


https://github.com/user-attachments/assets/cceeb446-56a0-41b1-983e-124890ad4b22


## How to Run This Project

1. Clone the repository:
```
git clone https://github.com/your-username/realtime-tfod.git
cd realtime-tfod
```
2. Set up a virtual environment:
```
python -m venv venv
source venv/bin/activate.ps1   # On Windows use `venv\Scripts\activate.ps1`
```
3. Install required dependencies:
```
Install required dependencies:
```
4. Create Your Gesture Dataset:
```
Run the Script Image Collection.ipynb
```
5. Train the model and do realtime gesture detection
```
Run the Script Training and Detection.ipynb
```

This setup will allow you to run the Human Emotion Detection system locally.
